import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import urllib.request
import os
import io
import csv
from datetime import date, timedelta

# --- å®Œç’§ãªæ—¥æœ¬èªžãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ---
FONT_URL = "https://github.com/google/fonts/raw/main/ofl/notosansjp/NotoSansJP%5Bwght%5D.ttf"
FONT_PATH = "NotoSansJP.ttf"

@st.cache_data
def load_font():
    if not os.path.exists(FONT_PATH):
        urllib.request.urlretrieve(FONT_URL, FONT_PATH)
    fm.fontManager.addfont(FONT_PATH)
    prop = fm.FontProperties(fname=FONT_PATH)
    plt.rcParams["font.family"] = prop.get_name()
    plt.rcParams["axes.unicode_minus"] = False
    return prop

try:
    font_prop = load_font()
    has_font = True
except Exception:
    font_prop = None
    has_font = False

st.set_page_config(page_title="Rapsodo Analyzer", layout="wide")


def _decode_bytes(b: bytes):
    """utf-8 ãŒãƒ€ãƒ¡ãªã‚‰ cp932 ã§èª­ã‚€ï¼ˆRapsodo CSVå¯¾ç­–ï¼‰"""
    for enc in ("utf-8", "cp932", "shift_jis"):
        try:
            return b.decode(enc), enc
        except Exception:
            pass
    return b.decode("utf-8", errors="ignore"), "utf-8(ignore)"


def process_data(uploaded_file):
    file_id = uploaded_file.name[:7]
    try:
        raw = uploaded_file.getvalue()
        text, used_enc = _decode_bytes(raw)
        lines = text.splitlines()

        # 3è¡Œç›®ã®2åˆ—ç›®ã‚’é¸æ‰‹åã¨ã—ã¦å–å¾—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«ä¾å­˜ï¼‰
        player_name = "Unknown"
        if len(lines) >= 3:
            reader = csv.reader([lines[2]])
            row3 = next(reader, [])
            if len(row3) >= 2:
                player_name = row3[1].strip() or "Unknown"

        # pandas ç”¨ã« BytesIO ã§èª­ã¿ç›´ã™
        bio = io.BytesIO(raw)
        df = pd.read_csv(bio, skiprows=4, encoding=used_enc)
        df.columns = [c.strip().replace('"', "") for c in df.columns]

        rename_dict = {
            "Pitch Type": "çƒç¨®",
            "Velocity": "çƒé€Ÿ",
            "Total Spin": "å›žè»¢æ•°",
            "True Spin (release)": "ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ”ãƒ³",
            "Spin Efficiency (release)": "å›žè»¢åŠ¹çŽ‡",
            "VB (trajectory)": "é«˜ã•å¤‰åŒ–",
            "HB (trajectory)": "æ¨ªå¤‰åŒ–",
            "Date": "æ—¥ä»˜",
            "Is Strike": "åˆ¤å®š",
        }
        df = df.rename(columns=rename_dict)

        # å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯
        required = ["çƒç¨®", "çƒé€Ÿ", "æ—¥ä»˜"]
        for col in required:
            if col not in df.columns:
                raise ValueError(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {col}")

        # ã€Œ-ã€ã¨ã€ŒOtherã€ã‚’é™¤å¤–
        df = df[~df["çƒç¨®"].isin(["-", "Other"])]

        # æ—¥ä»˜å‡¦ç†
        df["datetime"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
        df["æ—¥ä»˜"] = df["datetime"].dt.date

        # ã‚¹ãƒˆãƒ©ã‚¤ã‚¯åˆ—
        if "åˆ¤å®š" in df.columns:
            df["ã‚¹ãƒˆãƒ©ã‚¤ã‚¯æ•°"] = df["åˆ¤å®š"].map({"Y": 1, "N": 0}).fillna(0)
        else:
            df["ã‚¹ãƒˆãƒ©ã‚¤ã‚¯æ•°"] = 0

        # æ•°å€¤å¤‰æ›
        target_cols = ["çƒé€Ÿ", "å›žè»¢æ•°", "ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ”ãƒ³", "å›žè»¢åŠ¹çŽ‡", "é«˜ã•å¤‰åŒ–", "æ¨ªå¤‰åŒ–"]
        for col in target_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col].replace("-", pd.NA), errors="coerce")

        # è§£æžã«å¿…è¦ãªæ¬ æã‚’è½ã¨ã™
        df = df.dropna(subset=["çƒé€Ÿ", "çƒç¨®", "datetime"])

        return player_name, file_id, df

    except Exception as e:
        st.error(f"è§£æžã‚¨ãƒ©ãƒ¼: {e}")
        return "Error", file_id, pd.DataFrame()


def create_summary(df):
    """çƒç¨®åˆ¥ã«å¹³å‡ãªã©ã‚’é›†è¨ˆã—ã¦DataFrameã§è¿”ã™"""
    if df.empty:
        return pd.DataFrame()

    summary = df.groupby("çƒç¨®").agg(
        çƒé€Ÿå¹³å‡=("çƒé€Ÿ", "mean"),
        çƒé€Ÿæœ€å¤§=("çƒé€Ÿ", "max"),
        å›žè»¢æ•°=("å›žè»¢æ•°", "mean"),
        ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ”ãƒ³=("ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ”ãƒ³", "mean"),
        å›žè»¢åŠ¹çŽ‡=("å›žè»¢åŠ¹çŽ‡", "mean"),
        å¤‰åŒ–é‡é«˜ã•=("é«˜ã•å¤‰åŒ–", "mean"),
        å¤‰åŒ–é‡æ¨ª=("æ¨ªå¤‰åŒ–", "mean"),
        ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡=("ã‚¹ãƒˆãƒ©ã‚¤ã‚¯æ•°", "mean"),
        æŠ•çƒæ•°=("çƒé€Ÿ", "count"),
    ).reset_index()

    summary["ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡(%)"] = summary["ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡"] * 100

    # å¯¾FBæ¯”ï¼ˆFastball ãŒã‚ã‚‹å ´åˆï¼‰
    if (summary["çƒç¨®"] == "Fastball").any():
        fb_v = summary.loc[summary["çƒç¨®"] == "Fastball", "çƒé€Ÿå¹³å‡"].iloc[0]
        summary["çƒé€Ÿæ¯”çŽ‡(å¯¾FB %)"] = (summary["çƒé€Ÿå¹³å‡"] / fb_v) * 100

    # è¦‹ã›æ–¹ï¼šå†…éƒ¨åˆ—ã€Œã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡ã€ã¯éžè¡¨ç¤º
    show_cols = [c for c in summary.columns if c not in ["ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡"]]
    return summary[show_cols]


def main():
    st.title("âš¾ ãƒ©ãƒ—ã‚½ãƒ¼ãƒ‰è§£æžã‚·ã‚¹ãƒ†ãƒ ")
    files = st.file_uploader("CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", accept_multiple_files=True)

    if not files:
        st.info("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨è§£æžçµæžœã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        return

    for file in files:
        p_name, f_id, df = process_data(file)
        if df.empty:
            continue

        st.header(f"ðŸ“Š {p_name} ã®ãƒ©ãƒ—ã‚½ãƒ¼ãƒ‰è³‡æ–™")

        # çƒç¨®ã”ã¨ã®è‰²ã‚’å›ºå®š
        unique_pitches = sorted(df["çƒç¨®"].unique())
        pitch_colors = dict(zip(unique_pitches, sns.color_palette("husl", len(unique_pitches))))

        # æ—¥åˆ¥ï¼ˆçƒç¨®åˆ¥ï¼‰ã®çƒé€Ÿå¹³å‡ãƒ»æœ€å¤§
        daily_stats = df.groupby(["æ—¥ä»˜", "çƒç¨®"])["çƒé€Ÿ"].agg(["mean", "max"]).reset_index()

        # --- ã‚°ãƒ©ãƒ•æç”» ---
        col_g1, col_g2 = st.columns(2)

        with col_g1:
            fig_avg, ax_avg = plt.subplots()
            sns.lineplot(
                data=daily_stats, x="æ—¥ä»˜", y="mean",
                hue="çƒç¨®", marker="o", ax=ax_avg, palette=pitch_colors
            )
            title_txt, x_txt, y_txt = ("çƒé€Ÿï¼ˆå¹³å‡å€¤ï¼‰", "æ—¥ä»˜", "çƒé€Ÿ") if has_font else ("Velocity (Avg)", "Date", "Velocity")
            ax_avg.set_title(title_txt)
            ax_avg.set_xlabel(x_txt)
            ax_avg.set_ylabel(y_txt)
            plt.xticks(rotation=45)
            ax_avg.legend(prop=font_prop) if has_font else ax_avg.legend()
            st.pyplot(fig_avg)

        with col_g2:
            fig_mov, ax_mov = plt.subplots(figsize=(6, 6))
            sns.scatterplot(
                data=df, x="æ¨ªå¤‰åŒ–", y="é«˜ã•å¤‰åŒ–",
                hue="çƒç¨®", s=100, ax=ax_mov, palette=pitch_colors
            )
            title_txt, x_txt, y_txt = ("å¤‰åŒ–é‡ãƒ—ãƒ­ãƒƒãƒˆ", "æ¨ªå¤‰åŒ–", "é«˜ã•å¤‰åŒ–") if has_font else ("Movement", "HB", "VB")
            ax_mov.set_title(title_txt)
            ax_mov.set_xlabel(x_txt)
            ax_mov.set_ylabel(y_txt)
            ax_mov.axhline(0, linewidth=1)
            ax_mov.axvline(0, linewidth=1)
            ax_mov.legend(prop=font_prop) if has_font else ax_mov.legend()
            st.pyplot(fig_mov)

        # =========================
        # ã‚µãƒžãƒªãƒ¼ï¼ˆå…¨ä½“ / ç›´è¿‘30æ—¥ / å‰æœˆ30æ—¥ / å·®åˆ†ï¼‰
        # =========================
        st.subheader("ðŸ“Œ çƒç¨®åˆ¥ã‚µãƒžãƒªãƒ¼ï¼ˆå…¨ä½“ / ç›´è¿‘30æ—¥ / å‰æœˆ30æ—¥ï¼‰")

        today = date.today()
        this_start = today - timedelta(days=29)
        this_end = today
        prev_start = this_start - timedelta(days=30)
        prev_end = this_start - timedelta(days=1)

        df_all = df.copy()
        df_this = df[(df["æ—¥ä»˜"] >= this_start) & (df["æ—¥ä»˜"] <= this_end)].copy()
        df_prev = df[(df["æ—¥ä»˜"] >= prev_start) & (df["æ—¥ä»˜"] <= prev_end)].copy()

        sum_all = create_summary(df_all)
        sum_this = create_summary(df_this)
        sum_prev = create_summary(df_prev)

        fmt = {
            "çƒé€Ÿå¹³å‡": "{:.1f}",
            "çƒé€Ÿæœ€å¤§": "{:.1f}",
            "å›žè»¢æ•°": "{:.0f}",
            "ãƒˆã‚¥ãƒ«ãƒ¼ã‚¹ãƒ”ãƒ³": "{:.0f}",
            "å›žè»¢åŠ¹çŽ‡": "{:.1f}",
            "å¤‰åŒ–é‡é«˜ã•": "{:.1f}",
            "å¤‰åŒ–é‡æ¨ª": "{:.1f}",
            "ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡(%)": "{:.1f}",
            "çƒé€Ÿæ¯”çŽ‡(å¯¾FB %)": "{:.1f}",
        }

        c1, c2, c3 = st.columns(3)

        with c1:
            st.markdown("### å…¨ä½“")
            if sum_all.empty:
                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—")
            else:
                st.dataframe(sum_all.style.format(fmt), use_container_width=True)

        with c2:
            st.markdown(f"### ç›´è¿‘30æ—¥ï¼ˆ{this_start}ã€œ{this_end}ï¼‰")
            if sum_this.empty:
                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæœŸé–“å†…ã®æŠ•çƒãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
            else:
                st.dataframe(sum_this.style.format(fmt), use_container_width=True)

        with c3:
            st.markdown(f"### å‰æœˆ30æ—¥ï¼ˆ{prev_start}ã€œ{prev_end}ï¼‰")
            if sum_prev.empty:
                st.info("ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆæœŸé–“å†…ã®æŠ•çƒãŒã‚ã‚Šã¾ã›ã‚“ï¼‰")
            else:
                st.dataframe(sum_prev.style.format(fmt), use_container_width=True)

        st.subheader("ðŸ“ˆ å·®åˆ†ï¼ˆç›´è¿‘30æ—¥ âˆ’ å‰æœˆ30æ—¥ï¼‰")
        if (not sum_this.empty) and (not sum_prev.empty):
            a = sum_this.set_index("çƒç¨®")
            b = sum_prev.set_index("çƒç¨®")
            common = a.index.intersection(b.index)

            diff_cols = ["çƒé€Ÿå¹³å‡", "å›žè»¢æ•°", "å›žè»¢åŠ¹çŽ‡", "å¤‰åŒ–é‡é«˜ã•", "å¤‰åŒ–é‡æ¨ª", "ã‚¹ãƒˆãƒ©ã‚¤ã‚¯çŽ‡(%)"]
            # ç‰‡æ–¹ã«ã—ã‹ãªã„çƒç¨®ã¯æ¯”è¼ƒã§ããªã„ã®ã§ common ã®ã¿
            diff = (a.loc[common, diff_cols] - b.loc[common, diff_cols]).reset_index()

            st.dataframe(diff.style.format({c: "{:.1f}" for c in diff_cols}), use_container_width=True)
        else:
            st.info("ç›´è¿‘30æ—¥ã¾ãŸã¯å‰æœˆ30æ—¥ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚å·®åˆ†ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")


if __name__ == "__main__":
    main()
